{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00_preprocess.ipynb\n",
    "### Preprocess Gridded Data to find Anomalies and Extreme Values\n",
    "\n",
    "This notebook provides an example of how one might preprocess gridded sea surface temperature (SST) data to extract anomalies and detect extreme values. Here we will use monthly mean SST from the [NOAA Optimum Interpolation Sea Surface Temperature](https://www.ncdc.noaa.gov/oisst/data-access) (OISST v2.1) dataset. This data is measured from a blend of satellite and in-situ observations. We elect to use data from AVHRR-only satellites. This product is available from September 1981 through present on a 1/4º global regular grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data\n",
    "- load the daily OISST dataset and resample to monthly means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_url = 'https://ncsa.osn.xsede.org'\n",
    "fs_osn = s3fs.S3FileSystem(anon=True, client_kwargs={'endpoint_url': endpoint_url},) \n",
    "\n",
    "path = \"Pangeo/pangeo-forge/noaa_oisst/v2.1-avhrr.zarr\"\n",
    "ds = xr.open_zarr(fs_osn.get_mapper(path), consolidated=True).resample(time='MS').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds.load();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform time into decimal year and add it as a new coordinate --> `ds.dyr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = pd.DatetimeIndex(ds.time.values).year\n",
    "months = pd.DatetimeIndex(ds.time.values).month\n",
    "dyr = []\n",
    "for i in enumerate(years):\n",
    "    I = i[1] + ((months[i[0]]-0.5)/12)\n",
    "    dyr.append(I)\n",
    "ds['dyr'] = np.array(dyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decompose SST fields into mean, trend, annual, and semi-annual harmonics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our 6 coefficient model is composed of the mean, trend, annual sine and cosine harmonics, & semi-annual sine and cosine harmonics\n",
    "model = np.array([np.ones(len(ds.dyr))] + [dyr-np.mean(ds.dyr.values)] + [np.sin(2*np.pi*ds.dyr.values)] + [np.cos(2*np.pi*ds.dyr.values)] + [np.sin(4*np.pi*ds.dyr.values)] + [np.cos(4*np.pi*ds.dyr.values)])\n",
    "\n",
    "# Take the pseudo-inverse of model to 'solve' least-squares problem\n",
    "pmodel = np.linalg.pinv(model)\n",
    "\n",
    "# Convert model and pmodel to xaray DataArray\n",
    "model_da = xr.DataArray(model.T, dims=['time','coeff'], coords={'time':ds.time.values, 'coeff':np.arange(1,7,1)}) \n",
    "pmodel_da = xr.DataArray(pmodel.T, dims=['coeff','time'], coords={'coeff':np.arange(1,7,1), 'time':ds.time.values})  \n",
    "\n",
    "# resulting coefficients of the model\n",
    "sst_mod = xr.DataArray(pmodel_da.dot(ds.sst.isel(zlev=0)), dims=['coeff','lat','lon'], coords={'coeff':np.arange(1,7,1), 'lat':ds.lat.values, 'lon':ds.lon.values})  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction of the mean, trend, and seasonal cycle\n",
    "mean = xr.DataArray(model_da[:,0].dot(sst_mod[0,:,:]), dims=['time','lat','lon'], coords={'time':ds.time, 'lat':ds.lat.values, 'lon':ds.lon.values})   \n",
    "trend = xr.DataArray(model_da[:,1].dot(sst_mod[1,:,:]), dims=['time','lat','lon'], coords={'time':ds.time, 'lat':ds.lat.values, 'lon':ds.lon.values})    \n",
    "seas = xr.DataArray(model_da[:,2:].dot(sst_mod[2:,:,:]), dims=['time','lat','lon'], coords={'time':ds.time, 'lat':ds.lat.values, 'lon':ds.lon.values})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the SST anomalies with and without the trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine SST with and without the trend\n",
    "sst_notrend = xr.DataArray((ds.sst.isel(zlev=0)-trend).values, dims=['time','lat','lon'], coords={'time':ds.time, 'lat':ds.lat.values, 'lon':ds.lon.values})  \n",
    "sst_trend = xr.DataArray(ds.sst.isel(zlev=0).values, dims=['time','lat','lon'], coords={'time':ds.time, 'lat':ds.lat.values, 'lon':ds.lon.values})  \n",
    "\n",
    "# compute anomalies (SSTa) by removing model coefficients – with and without the trend\n",
    "ssta_notrend = xr.DataArray((ds.sst.isel(zlev=0).values-model_da.dot(sst_mod)).values, dims=['time','lat','lon'], coords={'time':ds.time, 'lat':ds.lat.values, 'lon':ds.lon.values}) \n",
    "ssta_trend = xr.DataArray((ds.sst.isel(zlev=0).values-model_da.dot(sst_mod[[0,2,3,4,5],:,:])).values, dims=['time','lat','lon'], coords={'time':ds.time, 'lat':ds.lat.values, 'lon':ds.lon.values})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Nino SST Indices (https://climatedataguide.ucar.edu/climate-data/nino-sst-indices-nino-12-3-34-4-oni-and-tni) as SST anomalies averaged across the respected region defined below:\n",
    "- Niño 3 (5N-5S, 150W-90W)\n",
    "- Niño 3.4 (5N-5S, 170W-120W)\n",
    "- Niño 4 (5N-5S, 160E-150W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nino3 = ssta_notrend.sel(lat=slice(-5, 5), lon=slice(210, 270)).mean(('lat','lon'))\n",
    "Nino3_4 = ssta_notrend.sel(lat=slice(-5, 5), lon=slice(190, 240)).mean(('lat','lon'))\n",
    "Nino4 = ssta_notrend.sel(lat=slice(-5, 5), lon=slice(200, 210)).mean(('lat','lon'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regress Nino indices from detrended SST anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = np.array([Nino3], [Nino3_4], [Nino4])\n",
    "pmodel = np.linalg.pinv(model)\n",
    "model_da = xr.DataArray(model.T, dims=['time','coeff'], coords={'time':ds.time.values, 'coeff':np.arange(1,4,1)}) \n",
    "pmodel_da = xr.DataArray(pmodel.T, dims=['coeff','time'], coords={'coeff':np.arange(1,4,1), 'time':ds.time.values})  \n",
    "Nino_mod = xr.DataArray(pmodel_da.dot(ssta_notrend), dims=['coeff','lat','lon'], coords={'coeff':np.arange(1,7,1), 'lat':ds.lat.values, 'lon':ds.lon.values})  \n",
    "\n",
    "sst_notrend_noNino3 = xr.DataArray((ssta_notrend.values-model_da.dot(Nino_mod[0,:,:])).values, dims=['time','lat','lon'], coords={'time':ds.time, 'lat':ds.lat.values, 'lon':ds.lon.values}) \n",
    "sst_notrend_noNino3_4 = xr.DataArray((ssta_notrend.values-model_da.dot(Nino_mod[1,:,:])).values, dims=['time','lat','lon'], coords={'time':ds.time, 'lat':ds.lat.values, 'lon':ds.lon.values}) \n",
    "sst_notrend_noNino4 = xr.DataArray((ssta_notrend.values-model_da.dot(Nino_mod[2,:,:])).values, dims=['time','lat','lon'], coords={'time':ds.time, 'lat':ds.lat.values, 'lon':ds.lon.values}) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our 6 coefficient model is composed of the mean, trend, annual sine and cosine harmonics, & semi-annual sine and cosine harmonics\n",
    "model = np.array([np.ones(len(dyr))] + [dyr-np.mean(dyr)] + [np.sin(2*np.pi*dyr)] + [np.cos(2*np.pi*dyr)] + [np.sin(4*np.pi*dyr)] + [np.cos(4*np.pi*dyr)])\n",
    "\n",
    "# Take the pseudo-inverse of model to 'solve' least-squares problem\n",
    "pmodel = np.linalg.pinv(model)\n",
    "\n",
    "# Convert model and pmodel to xaray DataArray\n",
    "model_da = xr.DataArray(model.T, dims=['time','coeff'], coords={'time':mnsst.time.values, 'coeff':np.arange(1,7,1)}) \n",
    "pmodel_da = xr.DataArray(pmodel.T, dims=['coeff','time'], coords={'coeff':np.arange(1,7,1), 'time':mnsst.time.values})  \n",
    "\n",
    "# resulting coefficients of the model\n",
    "sst_mod = xr.DataArray(pmodel_da.dot(mnsst), dims=['coeff','lat','lon'], coords={'coeff':np.arange(1,7,1), 'lat':mnsst.lat.values, 'lon':mnsst.lon.values})  \n",
    "\n",
    "# Construction of the mean, trend, and seasonal cycle\n",
    "mean = xr.DataArray(model_da[:,0].dot(sst_mod[0,:,:]), dims=['time','lat','lon'], coords={'time':mnsst.time, 'lat':mnsst.lat.values, 'lon':mnsst.lon.values})   \n",
    "trend = xr.DataArray(model_da[:,1].dot(sst_mod[1,:,:]), dims=['time','lat','lon'], coords={'time':mnsst.time, 'lat':mnsst.lat.values, 'lon':mnsst.lon.values})    \n",
    "seas = xr.DataArray(model_da[:,2:].dot(sst_mod[2:,:,:]), dims=['time','lat','lon'], coords={'time':mnsst.time, 'lat':mnsst.lat.values, 'lon':mnsst.lon.values})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compute SST anomalies (SSTa) and detrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine SST with and without the trend\n",
    "sst_notrend = xr.DataArray((mnsst-trend).values, dims=['time','lat','lon'], coords={'time':mnsst.time, 'lat':mnsst.lat.values, 'lon':mnsst.lon.values})  \n",
    "sst_trend = xr.DataArray(mnsst.values, dims=['time','lat','lon'], coords={'time': mnsst.time, 'lat':mnsst.lat.values, 'lon':mnsst.lon.values})  \n",
    "\n",
    "# compute anomalies (SSTa) by removing model coefficients – with and without the trend\n",
    "ssta_notrend = xr.DataArray((mnsst.values-model_da.dot(sst_mod)).values, dims=['time','lat','lon'], coords={'time':mnsst.time, 'lat':mnsst.lat.values, 'lon':mnsst.lon.values}) \n",
    "ssta_trend = xr.DataArray((mnsst.values-model_da.dot(sst_mod[[0,2,3,4,5],:,:])).values, dims=['time','lat','lon'], coords={'time':mnsst.time, 'lat':mnsst.lat.values, 'lon':mnsst.lon.values})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Standardized SSTa by dividing by the monthly standard deviation\n",
    "This step places equal variance on SSTa at all spatial points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute monthly standard deviation\n",
    "stdev_notrend = ssta_notrend.groupby(ssta_notrend.time.dt.month).std()\n",
    "stdev_trend = ssta_trend.groupby(ssta_trend.time.dt.month).std()\n",
    "\n",
    "# Initalize xarray DataArray for SSTa with and without trend\n",
    "ssta_stn_notrend = np.empty((ssta_notrend.shape[0], ssta_notrend.shape[1], ssta_notrend.shape[2])) \n",
    "ssta_stn_notrend[:] = np.nan\n",
    "ssta_stn_notrend = xr.DataArray(ssta_stn_notrend, dims=['time','lat','lon'], coords={'time':mnsst.time, 'lat':mnsst.lat.values, 'lon':mnsst.lon.values}) \n",
    "\n",
    "ssta_stn_trend = np.empty((ssta_trend.shape[0], ssta_trend.shape[1], ssta_trend.shape[2])) \n",
    "ssta_stn_trend[:] = np.nan\n",
    "ssta_stn_trend = xr.DataArray(ssta_stn_trend, dims=['time','lat','lon'], coords={'time':mnsst.time, 'lat':mnsst.lat.values, 'lon':mnsst.lon.values}) \n",
    "\n",
    "# Loop over months and divde by standard deviation\n",
    "for i in np.arange(1,13):\n",
    "    I = np.where(mnsst.time.dt.month==i)[0]\n",
    "    ssta_stn_notrend[I,:,:] = ssta_notrend[I,:,:]/stdev_notrend[i-1,:,:]\n",
    "    ssta_stn_trend[I,:,:] = ssta_trend[I,:,:]/stdev_trend[i-1,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Define a threshold to define extreme values\n",
    "Here we will use the 90th percentile relative to the monthly values over the entire record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define extreme threshold as the 90th percentile\n",
    "thresh = .9\n",
    "\n",
    "# Compute values of the monthly threshold\n",
    "prct_notrend = ssta_stn_notrend.quantile(thresh, dim='time', keep_attrs=True, skipna=True)\n",
    "prct_trend = ssta_stn_trend.quantile(thresh, dim='time', keep_attrs=True, skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SSTa relative to the threshold defined above in Step 5. \n",
    "ssta_prc_notrend = ssta_stn_notrend - prct_notrend\n",
    "ssta_prc_trend = ssta_stn_trend - prct_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Intialize xarray DataArrays for SSTa relative to the threshold defined above in Step 5.\n",
    "# ssta_prc_notrend = np.empty((ssta_stn_notrend.shape[0], ssta_stn_notrend.shape[1], ssta_stn_notrend.shape[2])) \n",
    "# ssta_prc_notrend[:] = np.nan\n",
    "# ssta_prc_notrend = xr.DataArray(ssta_prc_notrend,\n",
    "#                                 dims=('time', 'lat', 'lon'),\n",
    "#                                 coords={'time': ssta_stn_notrend.time.values,\n",
    "#                                         'lat': ssta_stn_notrend.lat.values,\n",
    "#                                         'lon': ssta_stn_notrend.lon.values,\n",
    "#                                         'quantile':thresh}) \n",
    "\n",
    "# ssta_prc_trend = np.empty((ssta_stn_trend.shape[0], ssta_stn_trend.shape[1], ssta_stn_trend.shape[2])) \n",
    "# ssta_prc_trend[:] = np.nan\n",
    "# ssta_prc_trend = xr.DataArray(ssta_prc_trend,\n",
    "#                               dims=('time', 'lat', 'lon'),\n",
    "#                               coords={'time': ssta_stn_trend.time.values,\n",
    "#                                       'lat': ssta_stn_trend.lat.values,\n",
    "#                                       'lon': ssta_stn_trend.lon.values,\n",
    "#                                       'quantile':thresh})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop over months and compute SSTa relative to the threshold defined above in Step 5.  \n",
    "# for i in np.arange(1,13,1):\n",
    "#     I = np.where(mnsst.time.dt.month==i)[0]\n",
    "#     ssta_prc_notrend[I,:,:] = ssta_stn_notrend[I,:,:]-prct_notrend[i-1,:,:] \n",
    "#     ssta_prc_trend[I,:,:] = ssta_stn_trend[I,:,:]-prct_trend[i-1,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data by plotting maps of the (a) climatology, (b) standard deviation, (c) seasonal amplitude, and (d) trend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "\n",
    "cptpath = r'/glade/u/home/scanh/getcpt-master'\n",
    "sys.path.append(cptpath)\n",
    "import get_cpt \n",
    "\n",
    "##################################################\n",
    "# Compute the standard deviation of detrended SSTA anomalies\n",
    "stdev_global = ssta_notrend.std('time')\n",
    "stdev_global.load()\n",
    "\n",
    "# Here, we are only interested in the data between 70ºS and 65ºN\n",
    "stdev_global = stdev_global.sel(lat=slice(-70,65))\n",
    "mean_sst = mean[0,:,:].sel(lat=slice(-70,65))\n",
    "\n",
    "# Next, we will calculate the seasonal cycle amplitude\n",
    "S = seas+mean\n",
    "seas_amp = S.max('time') - S.min('time')\n",
    "# again only selecting data betwen 70ºS and 65ºN\n",
    "seas_amp = seas_amp.sel(lat=slice(-70,65))\n",
    "\n",
    "# The trend is calculated 1982-2012 or 1989-2019\n",
    "T = trend+mean\n",
    "T = T.sel(time=slice('1990-01-01','2020-12-01'))\n",
    "T = T.sel(lat=slice(-70,65))\n",
    "trend_slope = T[-1,:,:]-T[0,:,:]\n",
    "\n",
    "# Create a mask over the poles\n",
    "blobs_masked = ssta_notrend.where((ssta_notrend.lat < 65) & (ssta_notrend.lat > -70), drop=False, other=9999)\n",
    "mask = blobs_masked.where(blobs_masked == 9999, other=np.nan, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make figure \n",
    "plt.rc('xtick', labelsize=22) \n",
    "plt.rc('ytick', labelsize=22)\n",
    "fig = plt.figure(figsize=(30,15)) \n",
    "\n",
    "lon=211.125 \n",
    "lat=46.625 \n",
    "\n",
    "# (a) Climatology\n",
    "ax = plt.subplot(221, projection=ccrs.Robinson(central_longitude=200))\n",
    "# plt.gca().patch.set_color('.30')\n",
    "ax.add_feature(cfeature.LAND, facecolor='lightgrey', zorder=1) \n",
    "lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "lat_formatter = LatitudeFormatter()\n",
    "ax.xaxis.set_major_formatter(lon_formatter)\n",
    "ax.yaxis.set_major_formatter(lat_formatter)\n",
    "ax.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "cont = mean_sst.plot.pcolormesh(vmin=0, vmax=30, levels=np.arange(0,32,2),\n",
    "                                           cmap= get_cpt.get_cmap('/glade/u/home/scanh/getcpt-master/cpt/temperature.cpt'), extend='both',\n",
    "                                           transform=ccrs.PlateCarree(), zorder=0, \n",
    "                                           add_labels=False, add_colorbar=False)\n",
    "cbar = plt.colorbar(cont, fraction=0.022, pad=0.04)\n",
    "cbar.set_label(r\"Climatology ($\\rm^{\\circ}C$)\", fontsize=25)\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "ax.tick_params(which='major', width=1.3, length=7)\n",
    "ax.tick_params(which='minor', width=1, length=4)\n",
    "plt.contourf(mask.lon, mask.lat, mask[0,:,:], colors='none', hatches=['///','///'],transform=ccrs.PlateCarree())\n",
    "ax.set_global()\n",
    "plt.text(0.1,1.05, '(a)', size=32, horizontalalignment='right', transform=ax.transAxes)\n",
    "\n",
    "\n",
    "# (b) Standard Deviation\n",
    "ax = plt.subplot(222, projection=ccrs.Robinson(central_longitude=200))\n",
    "ax.add_feature(cfeature.LAND, facecolor='lightgrey', zorder=1) \n",
    "lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "lat_formatter = LatitudeFormatter()\n",
    "ax.xaxis.set_major_formatter(lon_formatter)\n",
    "ax.yaxis.set_major_formatter(lat_formatter)\n",
    "ax.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "cont = stdev_global[:,:].plot.pcolormesh(vmin=0, vmax=1.4, levels=np.arange(0,1.5,.1),\n",
    "                                           cmap= get_cpt.get_cmap('/glade/u/home/scanh/getcpt-master/cpt/seminf-haxby.cpt'), extend='max',\n",
    "                                           transform=ccrs.PlateCarree(), zorder=0, \n",
    "                                           add_labels=False, add_colorbar=False)\n",
    "cbar = plt.colorbar(cont, fraction=0.022, pad=0.04)\n",
    "cbar.set_label(r\"Standard Deviation ($\\rm^{\\circ}C$)\", fontsize=25)\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "ax.tick_params(which='major', width=1.3, length=7)\n",
    "ax.tick_params(which='minor', width=1, length=4)\n",
    "plt.contourf(mask.lon, mask.lat, mask[0,:,:], colors='none', hatches=['///','///'],transform=ccrs.PlateCarree())\n",
    "ax.set_global()\n",
    "plt.plot(lon,lat,'k*',ms=20,transform=ccrs.PlateCarree())\n",
    "plt.text(0.1,1.05, '(b)', size=32, horizontalalignment='right', transform=ax.transAxes)\n",
    "\n",
    "# (c) Seasonal Amplitude\n",
    "ax = plt.subplot(223, projection=ccrs.Robinson(central_longitude=200))\n",
    "ax.add_feature(cfeature.LAND, facecolor='lightgrey', zorder=1) \n",
    "lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "lat_formatter = LatitudeFormatter()\n",
    "ax.xaxis.set_major_formatter(lon_formatter)\n",
    "ax.yaxis.set_major_formatter(lat_formatter)\n",
    "ax.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "cont = seas_amp.plot.pcolormesh(vmin=0, vmax=20, levels=np.arange(0,17,1),\n",
    "                                           cmap= get_cpt.get_cmap('/glade/u/home/scanh/getcpt-master/cpt/precip2_17lev.cpt'), extend='max',\n",
    "                                           transform=ccrs.PlateCarree(), zorder=0, \n",
    "                                           add_labels=False, add_colorbar=False)\n",
    "cbar = plt.colorbar(cont, fraction=0.022, pad=0.04)\n",
    "cbar.set_label(r\"Seasonal Amplitude ($\\rm^{\\circ}C$)\", fontsize=25)\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "ax.tick_params(which='major', width=1.3, length=7)\n",
    "ax.tick_params(which='minor', width=1, length=4)\n",
    "plt.contourf(mask.lon, mask.lat, mask[0,:,:], colors='none', hatches=['///','///'],transform=ccrs.PlateCarree())\n",
    "ax.set_global()\n",
    "plt.text(0.1,1.05, '(c)', size=32, horizontalalignment='right', transform=ax.transAxes)\n",
    "\n",
    "# (d) Trend\n",
    "ax = plt.subplot(224, projection=ccrs.Robinson(central_longitude=200))\n",
    "ax.add_feature(cfeature.LAND, facecolor='lightgrey', zorder=1) \n",
    "lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "lat_formatter = LatitudeFormatter()\n",
    "ax.xaxis.set_major_formatter(lon_formatter)\n",
    "ax.yaxis.set_major_formatter(lat_formatter)\n",
    "ax.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "cont = trend_slope.plot.pcolormesh(vmin=-2, vmax=2, levels=np.arange(-2,2.2,.2),\n",
    "                                           cmap= get_cpt.get_cmap('/glade/u/home/scanh/getcpt-master/cpt/GMT_panoply.cpt'), extend='both',\n",
    "                                           transform=ccrs.PlateCarree(), zorder=0, \n",
    "                                           add_labels=False, add_colorbar=False)\n",
    "cbar = plt.colorbar(cont, fraction=0.022, pad=0.04)\n",
    "cbar.set_label(r\"Trend ($\\rm^{\\circ}C/30$ years)\", fontsize=25)\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "ax.tick_params(which='major', width=1.3, length=7)\n",
    "ax.tick_params(which='minor', width=1, length=4)\n",
    "plt.contourf(mask.lon, mask.lat, mask[0,:,:], colors='none', hatches=['///','///'],transform=ccrs.PlateCarree())\n",
    "ax.set_global()\n",
    "plt.text(0.1,1.05, '(d)', size=32, horizontalalignment='right', transform=ax.transAxes);\n",
    "\n",
    "\n",
    "# fig.savefig('/glade/u/home/scanh/figures/ocetrac_figures/Figure1_oisst_v02r01.png', bbox_inches='tight', format='png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Find where the standardized SSTa exceeds the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only the SSTa that exceeds the calculated monthly threshold\n",
    "mhw_ssta_notrend = ssta_stn_notrend.where(ssta_prc_notrend>0.)\n",
    "mhw_ssta_trend = ssta_stn_trend.where(ssta_prc_trend>0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon=211.125 \n",
    "lat=46.625 \n",
    "point_seas = seas.loc[dict(lon=lon, lat=lat)]\n",
    "point_mean = mean.loc[dict(lon=lon, lat=lat)]\n",
    "point_trend = trend.loc[dict(lon=lon, lat=lat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('xtick', labelsize=14) \n",
    "plt.rc('ytick', labelsize=14)\n",
    "fig = plt.figure(figsize=(10,8)) \n",
    "\n",
    "ax = plt.subplot(211)\n",
    "plt.text(-0.04,1.05, '(a)', size=20, horizontalalignment='right', transform=ax.transAxes);\n",
    "s = plt.plot(point_seas.time, point_seas+point_mean+point_trend, color='darkcyan', lw=4, alpha=0.7, label=r\"$\\rmSST_{fit}$\")\n",
    "plt.plot(mnsst.time, mnsst.loc[dict(lon=lon, lat=lat)], color='black', lw=3, label='SST')\n",
    "plt.xlim('2010-01-01',point_seas.time[-1].values);\n",
    "plt.ylim(5,17.9)\n",
    "plt.ylabel(r\"SST ($\\rm ^{\\circ}C$)\", fontsize=14)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.legend(frameon=False, ncol=2,loc='upper left', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "ax = plt.subplot(212)\n",
    "plt.text(-0.04,1.05, '(b)', size=20, horizontalalignment='right', transform=ax.transAxes);\n",
    "plt.plot(ssta_stn_notrend.time, np.zeros(len(ssta_stn_notrend.time)), color='k', lw=1, alpha=0.4)\n",
    "plt.plot(ssta_stn_notrend.time, np.ones(len(ssta_stn_notrend.time))*prct_notrend.loc[dict(lon=lon, lat=lat)].values, '--', color='k', lw=2)\n",
    "plt.plot(ssta_notrend.time, ssta_notrend.loc[dict(lon=lon, lat=lat)], color='gray', lw=2, label=r\"$\\rmSSTa$\")\n",
    "plt.plot(ssta_stn_notrend.time, ssta_stn_notrend.loc[dict(lon=lon, lat=lat)], color='darkred', lw=2, label=r\"$\\rmSSTa^{*}$\")\n",
    "plt.plot(mhw_ssta_notrend.time, mhw_ssta_notrend.loc[dict(lon=lon, lat=lat)],'r.', ms=10)\n",
    "plt.xlim('2010-01-01',point_seas.time[-1].values);\n",
    "# plt.ylim(5,17.9)\n",
    "plt.ylabel(r\"$\\rmSSTa$ ($\\rm ^{\\circ}C$)\", fontsize=14)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.legend(frameon=False, ncol=2,loc='upper left', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Save the extreme values of SSTa relative to the mean in netCDF format\n",
    "! Need to add land mask to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path to save output \n",
    "save_to = '/glade/scratch/scanh/MHW_pre/'\n",
    "\n",
    "# Convert xarray DatAarray to Dataset\n",
    "mhw_ssta_notrend.compute()\n",
    "mhw_ssta_notrend_ds = mhw_ssta_notrend.to_dataset(name='mhw_ssta_notrend')\n",
    "mhw_ssta_notrend_ds['mask'] = dm.lsmask[0,:,:]\n",
    "mhw_ssta_notrend_ds.attrs['threshold'] = 0.9\n",
    "\n",
    "mhw_ssta_trend.compute()\n",
    "mhw_ssta_trend_ds = mhw_ssta_trend.to_dataset(name='mhw_ssta_trend')\n",
    "mhw_ssta_trend_ds['mask'] = dm.lsmask[0,:,:]\n",
    "mhw_ssta_trend_ds.attrs['threshold'] = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dataset to netCDF\n",
    "mhw_ssta_notrend_ds.to_netcdf(save_to+'preprocess_mhw_OISSTv2_monthly_notrend_stn.nc', mode='w')\n",
    "\n",
    "mhw_ssta_trend_ds.to_netcdf(save_to+'preprocess_mhw_OISSTv2_monthly_trend_stn.nc', mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mhw_ssta_notrend_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marine-heatwaves",
   "language": "python",
   "name": "marine-heatwaves"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
